{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:34:42.727439Z",
     "start_time": "2019-05-01T11:34:42.722241Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import MeanShift, KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign Attack Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:34:42.742229Z",
     "start_time": "2019-05-01T11:34:42.729903Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def attackIntance(label):\n",
    "\n",
    "    # Define attack categories by dataset labels\n",
    "    normal = ['normal']\n",
    "    dos = ['neptune', 'back', 'teardrop', 'smurf', 'pod', 'land']\n",
    "    probe = ['portsweep', 'satan', 'ipsweep', 'nmap']\n",
    "    r2l = ['warezclient', 'multihop', 'ftp_write', 'imap', 'guess_passwd', 'warezmaster', 'spy', 'phf']\n",
    "    u2r = ['buffer_overflow', 'loadmodule', 'rootkit', 'perl']\n",
    "\n",
    "    # Return the relevant attack category for each given label\n",
    "    if label in normal:\n",
    "        return 'normal'\n",
    "    elif label in dos:\n",
    "        return 'dos'\n",
    "    elif label in probe:\n",
    "        return 'probe'\n",
    "    elif label in r2l:\n",
    "        return 'r2l'\n",
    "    elif label in u2r:\n",
    "        return 'u2r'\n",
    "\n",
    "def attackDF(df):\n",
    "\n",
    "    # Apply attackIntance function to given dataframe\n",
    "    df['attack'] = df.apply(lambda row: attackIntance(row.label), axis=1)\n",
    "\n",
    "    # Return dataframe after attack categorisation\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelise Dataframe Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:34:42.760162Z",
     "start_time": "2019-05-01T11:34:42.743931Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "\n",
    "    # Number of cores on your machine\n",
    "    num_cores = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    # Number of partitions to split dataframe\n",
    "    num_partitions = num_cores\n",
    "\n",
    "    # Split dataframe\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "\n",
    "    # Create multiprocesing pool using number of cores\n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "\n",
    "    # Close and join pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Return merged dataframe\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster & Compare Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:34:42.780208Z",
     "start_time": "2019-05-01T11:34:42.762824Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def ClusterANDCompareOptimised(df, attack, num_clusters):\n",
    "    \n",
    "    # Get instances with the label normal\n",
    "    df_filtered = df.loc[(df['attack'] == attack)]\n",
    "\n",
    "    labels = df_filtered['label']\n",
    "    del df_filtered['label']\n",
    "\n",
    "    attacks = df_filtered['attack']\n",
    "    del df_filtered['attack']\n",
    "\n",
    "    df_filtered = pd.get_dummies(df_filtered)\n",
    "\n",
    "    df_filtered_values = df_filtered.values\n",
    "    \n",
    "    # Standard Scalar\n",
    "    scaler = StandardScaler()\n",
    "    df_filtered_values_scaled = scaler.fit_transform(df_filtered_values)\n",
    "\n",
    "    # Apply PCA for 3 features\n",
    "    pca_model = PCA(n_components=3)\n",
    "    pca_model.fit(df_filtered_values_scaled)\n",
    "    df_filtered_values_pca = pca_model.transform(df_filtered_values_scaled)\n",
    "\n",
    "    model = KMeans(n_clusters=num_clusters, max_iter=1000)\n",
    "    model.fit(df_filtered_values_pca)\n",
    "    y = model.predict(df_filtered_values_pca)\n",
    "\n",
    "    predicted_labels = (y).tolist()\n",
    "\n",
    "    # actual_labels = attacks.tolist()\n",
    "\n",
    "    actual_labels = labels.tolist()\n",
    "    \n",
    "    df_filtered['predicted'] = predicted_labels\n",
    "    df_filtered['label'] = labels\n",
    "    df_filtered['attack'] = attacks\n",
    "    \n",
    "    # Print count of unique labels per each unique cluster\n",
    "    for predicted_label in df_filtered['predicted'].unique():\n",
    "        print('----------------------------------------------------------------------\\nPredicted Cluster:', predicted_label)\n",
    "        filtered = df_filtered.loc[df_filtered['predicted'] == predicted_label]\n",
    "        print('\\nUnique Counts:\\n', filtered.label.value_counts())\n",
    "        \n",
    "    return actual_labels, predicted_labels, scaler, pca_model, df_filtered\n",
    "\n",
    "# def ClusterANDCompare(df, attack, num_clusters):\n",
    "    \n",
    "#     # Get instances with the label normal\n",
    "#     df_filtered = df.loc[(df['attack'] == attack)]\n",
    "\n",
    "#     labels = df_filtered['label']\n",
    "#     del df_filtered['label']\n",
    "\n",
    "#     attacks = df_filtered['attack']\n",
    "#     del df_filtered['attack']\n",
    "\n",
    "#     df_filtered = pd.get_dummies(df_filtered)\n",
    "\n",
    "#     df_filtered_values = df_filtered.values\n",
    "    \n",
    "#     # Standard Scalar\n",
    "#     scaler = StandardScaler()\n",
    "#     df_filtered_values_scaled = scaler.fit_transform(df_filtered_values)\n",
    "\n",
    "#     # Apply PCA for 3 features\n",
    "#     pca_model = PCA(n_components=3)\n",
    "#     pca_model.fit(df_filtered_values_scaled)\n",
    "#     df_filtered_values_pca = pca_model.transform(df_filtered_values_scaled)\n",
    "\n",
    "#     model = KMeans(n_clusters=num_clusters, max_iter=1000)\n",
    "#     model.fit(df_filtered_values_pca)\n",
    "#     y = model.predict(df_filtered_values_pca)\n",
    "\n",
    "#     predicted_labels = (y).tolist()\n",
    "\n",
    "#     # actual_labels = attacks.tolist()\n",
    "\n",
    "#     actual_labels = labels.tolist()\n",
    "\n",
    "#     # Create list of dictionaries to store both predicted and actual labels\n",
    "#     dict_list = []\n",
    "\n",
    "#     for i in range(len(predicted_labels)):\n",
    "#         row_dict = {}\n",
    "#         row_dict['Predicted'] = predicted_labels[i]\n",
    "#         row_dict['Actual'] = actual_labels[i]\n",
    "#         dict_list.append(row_dict)\n",
    "\n",
    "#     # Create dataframe from list of dictionaries\n",
    "#     df_clustered = pd.DataFrame(dict_list)\n",
    "\n",
    "#     # Print count of unique labels per each unique cluster\n",
    "#     for predicted_label in df_clustered['Predicted'].unique():\n",
    "#         print('----------------------------------------------------------------------\\nPredicted Cluster:', predicted_label)\n",
    "#         filtered = df_clustered.loc[df_clustered['Predicted'] == predicted_label]\n",
    "#         print('\\nUnique Counts:\\n', filtered.Actual.value_counts())\n",
    "        \n",
    "#     return actual_labels, predicted_labels, pca_model, df_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataframe and get Relevant Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:01.127836Z",
     "start_time": "2019-05-01T11:32:56.095042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape: (145585, 43)\n",
      "\n",
      "Unique counts for each Label:\n",
      " normal             87831\n",
      "neptune            51820\n",
      "back                 968\n",
      "teardrop             918\n",
      "satan                906\n",
      "warezclient          893\n",
      "ipsweep              651\n",
      "smurf                641\n",
      "portsweep            416\n",
      "pod                  206\n",
      "nmap                 158\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  19\n",
      "imap                  12\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Unique counts for each Attack Category:\n",
      " normal    87831\n",
      "dos       54572\n",
      "probe      2131\n",
      "r2l         999\n",
      "u2r          52\n",
      "Name: attack, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                     1.0   \n",
       "1               0       0    0  ...                     1.0   \n",
       "2               0       0    0  ...                     1.0   \n",
       "3               0       0    0  ...                     1.0   \n",
       "4               0       0    0  ...                     1.0   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                     0.0                         0.11   \n",
       "1                     0.0                         0.05   \n",
       "2                     0.0                         0.03   \n",
       "3                     0.0                         0.03   \n",
       "4                     0.0                         0.02   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                          0.0                   0.0   \n",
       "1                          0.0                   0.0   \n",
       "2                          0.0                   0.0   \n",
       "3                          0.0                   0.0   \n",
       "4                          0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                   0.0                       0.0   \n",
       "1                       0.0                   0.0                       0.0   \n",
       "2                       0.0                   0.0                       0.0   \n",
       "3                       0.0                   0.0                       0.0   \n",
       "4                       0.0                   0.0                       0.0   \n",
       "\n",
       "    label  attack  \n",
       "0  normal  normal  \n",
       "1  normal  normal  \n",
       "2  normal  normal  \n",
       "3  normal  normal  \n",
       "4  normal  normal  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe\n",
    "df = pd.read_csv('kddcup99_csv.csv')\n",
    "\n",
    "# Assign attack categories by multiprocessing\n",
    "df = parallelize_dataframe(df, attackDF)\n",
    "\n",
    "# Drop duplicate data instances\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Print dataframe shape\n",
    "print('Dataframe Shape:', df.shape)\n",
    "\n",
    "# Print unique counts of each label and attack category\n",
    "print('\\nUnique counts for each Label:\\n', df.label.value_counts())\n",
    "print('\\nUnique counts for each Attack Category:\\n', df.attack.value_counts())\n",
    "\n",
    "# See dataframe head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filtrations to exclude Non-DoS Attacks, & Use only relevant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:03.525231Z",
     "start_time": "2019-05-01T11:33:03.501233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get datapoints with attack categories of normal and dos\n",
    "df = df.loc[(df['attack'] == 'normal') | (df['attack'] == 'dos')]\n",
    "\n",
    "# # Define relevant features to use in analysis\n",
    "# # relevant = ['diff_srv_rate', 'dst_bytes', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'flag', 'rerror_rate', 'same_srv_rate', 'service', 'src_bytes', 'wrong_fragment', 'label', 'attack' ]\n",
    "# relevant = ['duration', 'protocol_type', 'service', 'src_bytes', 'dst_bytes', 'flag', 'land', 'wrong_fragment', 'urgent', 'count', 'serror_rate', 'rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_count', 'srv_serror_rate', 'label', 'attack']\n",
    "# df = df[relevant]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Instances Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:06.767274Z",
     "start_time": "2019-05-01T11:33:06.012326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 1\n",
      "\n",
      "Unique Counts:\n",
      " normal    83096\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 0\n",
      "\n",
      "Unique Counts:\n",
      " normal    4735\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "normal_actual_labels, normal_predicted_labels, normal_scaler, normal_pca_model, normal_df_clustered = \\\n",
    "ClusterANDCompareOptimised(df, 'normal', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:10.787806Z",
     "start_time": "2019-05-01T11:33:10.769952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_REJ</th>\n",
       "      <th>flag_RSTO</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_S3</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>label</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "1593         0          0          0     0               0       0    0   \n",
       "1594         0          0          0     0               0       0    0   \n",
       "1595         0          0          0     0               0       0    0   \n",
       "1596         0          0          0     0               0       0    0   \n",
       "4906         0          0          0     0               0       0    0   \n",
       "\n",
       "      num_failed_logins  logged_in  lnum_compromised  ...  flag_REJ  \\\n",
       "1593                  0          0                 0  ...         1   \n",
       "1594                  0          0                 0  ...         1   \n",
       "1595                  0          0                 0  ...         1   \n",
       "1596                  0          0                 0  ...         1   \n",
       "4906                  0          0                 0  ...         1   \n",
       "\n",
       "      flag_RSTO  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
       "1593          0          0        0        0        0        0        0   \n",
       "1594          0          0        0        0        0        0        0   \n",
       "1595          0          0        0        0        0        0        0   \n",
       "1596          0          0        0        0        0        0        0   \n",
       "4906          0          0        0        0        0        0        0   \n",
       "\n",
       "       label  attack  \n",
       "1593  normal  normal  \n",
       "1594  normal  normal  \n",
       "1595  normal  normal  \n",
       "1596  normal  normal  \n",
       "4906  normal  normal  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out anaomly normal \n",
    "normal_df_clustered = normal_df_clustered.loc[normal_df_clustered['predicted']==0]\n",
    "del normal_df_clustered['predicted']\n",
    "normal_df_clustered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DoS Attacks Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:15.166203Z",
     "start_time": "2019-05-01T11:33:14.476996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 5\n",
      "\n",
      "Unique Counts:\n",
      " neptune    471\n",
      "land         3\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 4\n",
      "\n",
      "Unique Counts:\n",
      " teardrop    918\n",
      "pod          80\n",
      "smurf        21\n",
      "land         16\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 3\n",
      "\n",
      "Unique Counts:\n",
      " smurf    620\n",
      "pod      126\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 2\n",
      "\n",
      "Unique Counts:\n",
      " back    968\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 0\n",
      "\n",
      "Unique Counts:\n",
      " neptune    41554\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 1\n",
      "\n",
      "Unique Counts:\n",
      " neptune    9795\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dos_actual_labels, dos_predicted_labels, dos_scaler, dos_pca_model, dos_df_clustered = \\\n",
    "ClusterANDCompareOptimised(df, 'dos', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:20.158416Z",
     "start_time": "2019-05-01T11:33:20.078262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 1\n",
      "\n",
      "Unique Counts:\n",
      " pod    206\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 2\n",
      "\n",
      "Unique Counts:\n",
      " land    19\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 0\n",
      "\n",
      "Unique Counts:\n",
      " back    968\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_dos_filtered = df.loc[(df['label'] == 'back')|(df['label'] == 'land')|(df['label'] == 'pod')]\n",
    "dos_actual_labels_filtered, dos_predicted_labels_filtered, dos_scaler_filtered, dos_pca_model_filtered, \\\n",
    "dos_df_clustered_filtered = ClusterANDCompareOptimised(df_dos_filtered, 'dos', 3)\n",
    "del dos_df_clustered_filtered['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:26.802722Z",
     "start_time": "2019-05-01T11:33:26.786404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique counts for each Label:\n",
      " back    968\n",
      "pod     206\n",
      "land     19\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>lnum_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>service_http</th>\n",
       "      <th>service_telnet</th>\n",
       "      <th>service_tim_i</th>\n",
       "      <th>flag_RSTR</th>\n",
       "      <th>flag_S0</th>\n",
       "      <th>flag_S1</th>\n",
       "      <th>flag_S2</th>\n",
       "      <th>flag_SF</th>\n",
       "      <th>label</th>\n",
       "      <th>attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15785</th>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15786</th>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15787</th>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15788</th>\n",
       "      <td>0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>pod</td>\n",
       "      <td>dos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "15784         0       1480          0     0               1       0    0   \n",
       "15785         0       1480          0     0               1       0    0   \n",
       "15786         0       1480          0     0               1       0    0   \n",
       "15787         0       1480          0     0               1       0    0   \n",
       "15788         0       1480          0     0               1       0    0   \n",
       "\n",
       "       num_failed_logins  logged_in  lnum_compromised  ...  service_http  \\\n",
       "15784                  0          0                 0  ...             0   \n",
       "15785                  0          0                 0  ...             0   \n",
       "15786                  0          0                 0  ...             0   \n",
       "15787                  0          0                 0  ...             0   \n",
       "15788                  0          0                 0  ...             0   \n",
       "\n",
       "       service_telnet  service_tim_i  flag_RSTR  flag_S0  flag_S1  flag_S2  \\\n",
       "15784               0              0          0        0        0        0   \n",
       "15785               0              0          0        0        0        0   \n",
       "15786               0              0          0        0        0        0   \n",
       "15787               0              0          0        0        0        0   \n",
       "15788               0              0          0        0        0        0   \n",
       "\n",
       "       flag_SF  label  attack  \n",
       "15784        1    pod     dos  \n",
       "15785        1    pod     dos  \n",
       "15786        1    pod     dos  \n",
       "15787        1    pod     dos  \n",
       "15788        1    pod     dos  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print unique counts of each label\n",
    "print('\\nUnique counts for each Label:\\n', dos_df_clustered_filtered.label.value_counts())\n",
    "\n",
    "dos_df_clustered_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Datapoints into Normal & DoS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:33.325864Z",
     "start_time": "2019-05-01T11:33:33.307071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose n elements from each label\n",
    "Samplesize = 19  #number of samples that you want\n",
    "normal_df_clustered = normal_df_clustered.groupby('label', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:])\n",
    "\n",
    "# Choose n elements from each label\n",
    "Samplesize = 19  #number of samples that you want\n",
    "dos_df_clustered_filtered = dos_df_clustered_filtered.groupby('label', as_index=False).apply(lambda array: array.loc[np.random.choice(array.index, Samplesize, False),:])\n",
    "\n",
    "normal_labels = normal_df_clustered['label']\n",
    "normal_attacks = normal_df_clustered['attack']\n",
    "del normal_df_clustered['label']\n",
    "del normal_df_clustered['attack']\n",
    "\n",
    "dos_labels = dos_df_clustered_filtered['label']\n",
    "dos_attacks = dos_df_clustered_filtered['attack']\n",
    "del dos_df_clustered_filtered['label']\n",
    "del dos_df_clustered_filtered['attack']\n",
    "\n",
    "labels = normal_labels.tolist() + dos_labels.tolist()\n",
    "attacks = normal_attacks.tolist() + dos_attacks.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T11:33:39.796712Z",
     "start_time": "2019-05-01T11:33:39.760796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 3\n",
      "\n",
      "Unique Counts:\n",
      " normal    19\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 0\n",
      "\n",
      "Unique Counts:\n",
      " back    19\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 1\n",
      "\n",
      "Unique Counts:\n",
      " land    19\n",
      "Name: label, dtype: int64\n",
      "----------------------------------------------------------------------\n",
      "Predicted Cluster: 2\n",
      "\n",
      "Unique Counts:\n",
      " pod    19\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "normal_df_clustered_values = normal_df_clustered.values\n",
    "normal_df_clustered_values_scaled = normal_scaler.transform(normal_df_clustered_values)\n",
    "normal_df_clustered_values_pca = normal_pca_model.transform(normal_df_clustered_values_scaled)\n",
    "\n",
    "\n",
    "dos_df_clustered_filtered_values = dos_df_clustered_filtered.values\n",
    "dos_df_clustered_filtered_values_normal_scaled = dos_scaler_filtered.transform(dos_df_clustered_filtered_values)\n",
    "dos_df_clustered_filtered_values_normal_pca = dos_pca_model_filtered.transform(dos_df_clustered_filtered_values_normal_scaled)\n",
    "\n",
    "concatenated_data = np.concatenate((normal_df_clustered_values_pca, \\\n",
    "                                    dos_df_clustered_filtered_values_normal_pca))\n",
    "\n",
    "model = KMeans(n_clusters=4, max_iter=1000)\n",
    "model.fit(concatenated_data)\n",
    "y = model.predict(concatenated_data)\n",
    "\n",
    "predicted_labels = (y).tolist()\n",
    "\n",
    "# actual_labels = attacks\n",
    "\n",
    "actual_labels = labels\n",
    "\n",
    "df_filtered = pd.DataFrame()\n",
    "\n",
    "df_filtered['predicted'] = predicted_labels\n",
    "df_filtered['label'] = labels\n",
    "df_filtered['attack'] = attacks\n",
    "\n",
    "# Print count of unique labels per each unique cluster\n",
    "for predicted_label in df_filtered['predicted'].unique():\n",
    "    print('----------------------------------------------------------------------\\nPredicted Cluster:', predicted_label)\n",
    "    filtered = df_filtered.loc[df_filtered['predicted'] == predicted_label]\n",
    "    print('\\nUnique Counts:\\n', filtered.label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "# %%\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.cluster import MeanShift, AgglomerativeClustering\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n\nfrom collections import defaultdict\n\nfrom mpl_toolkits import mplot3d\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('kddcup99_csv.csv')\n\n# df = df.drop_duplicates()\n\nprint('Dataframe Shape:', df.shape)\n\nprint('Columns:\\n', list(df))\n\nprint('\\nUnique counts for each label:\\n', df.label.value_counts())\n\nlabels = df['label']\n\ndel df['label']\n\ndf = pd.get_dummies(df)\n\nprint('##################################################################################################\\n', df.head())\n\nX = df.values\n\nkmeans = KMeans(n_clusters=10)\nkmeans.fit(X)\ny_kmeans = kmeans.predict(X)\n\npredicted_labels = (y_kmeans).tolist()\n\nactual_labels = labels.tolist()\n\ndict_list = []\n\nfor i in range(len(predicted_labels)):\n    row_dict = {}\n    row_dict['Predicted'] = predicted_labels[i]\n    row_dict['Actual'] = actual_labels[i]\n    dict_list.append(row_dict)\n\nnew_dict = pd.DataFrame(dict_list)\n\nfor predicted_label in new_dict['Predicted'].unique():\n    print('----------------------------------------------------------------------\\nPredicted Cluster:', predicted_label)\n    filtered = new_dict.loc[new_dict['Predicted'] == predicted_label]\n    print('\\nUnique Counts:\\n', filtered.Actual.value_counts())"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
